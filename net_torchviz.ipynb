{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1xBWHGjGGZj"
   },
   "source": [
    "PyTorchViz examples\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrJjv2UAGGZr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\n",
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyXiCohjGGZt"
   },
   "source": [
    "## Visualize gradients of simple MLP\n",
    "\n",
    "The method below is for building directed graphs of PyTorch operations, built during forward propagation and showing which operations will be called on backward. It omits subgraphs which do not require gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLcALVSpGGZt",
    "outputId": "c46f4d64-95b5-4cee-dc11-9aa90b38acef"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('W0', nn.Linear(8, 16))\n",
    "model.add_module('tanh', nn.Tanh())\n",
    "model.add_module('W1', nn.Linear(16, 1))\n",
    "\n",
    "x = torch.randn(1,8)\n",
    "\n",
    "make_dot(model(x), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8HrECztGGZv"
   },
   "source": [
    "Specify `show_attrs=True` and `show_saved=True` to see what autograd saves for the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gdxm5RbGGZv",
    "outputId": "51727439-7e7b-4e0c-f533-0df24e8c768e"
   },
   "outputs": [],
   "source": [
    "make_dot(model(x), params=dict(model.named_parameters()), show_attrs=True, show_saved=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh8H2WZ1GGZw"
   },
   "source": [
    "## Double Backpropagation\n",
    "\n",
    "Implements \"Double Backpropagation\" from [Drucker and Lecun](http://yann.lecun.com/exdb/publis/pdf/drucker-lecun-92.pdf). The idea is to minimize the loss:\n",
    "\n",
    "$$f(x, \\theta) = f(x, \\theta) + g(\\frac{\\partial f(x, \\theta)}{\\partial x})$$\n",
    "\n",
    "where $x$ and $\\theta$ are input and parameter vectors, $f(x, \\theta)$ is the original loss function, and $g$ is a function of gradient w.r.t. input.\n",
    "\n",
    "This is used in [Improved Wasserstein GAN](https://arxiv.org/abs/1704.00028) and [Attention Transfer](https://arxiv.org/abs/1612.03928)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3KdQZtPGGZx",
    "outputId": "c42aeca7-bd46-4de5-ccf7-4fe3a95655b9"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(1,8).requires_grad_(True)\n",
    "\n",
    "def double_backprop(inputs, net):\n",
    "    y = net(x).mean()\n",
    "    grad,  = torch.autograd.grad(y, x, create_graph=True, retain_graph=True)\n",
    "    return grad.pow(2).mean() + y\n",
    "\n",
    "make_dot(double_backprop(x, model), params=dict(list(model.named_parameters()) + [('x', x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMarMnMjGGZy"
   },
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smZEIJDnGGZ0",
    "outputId": "88773232-dc5e-44f1-d1a4-2ba51bda3b7c"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import AlexNet\n",
    "\n",
    "model = AlexNet()\n",
    "\n",
    "x = torch.randn(1, 3, 227, 227).requires_grad_(True)\n",
    "y = model(x)\n",
    "make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCLTgsNzGGZ0"
   },
   "source": [
    "And AlexNet double backprop for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeDbM16zGGZ2",
    "outputId": "1f93fb7a-6f0a-439c-ef43-8245ade14169"
   },
   "outputs": [],
   "source": [
    "make_dot(double_backprop(x, model), params=dict(list(model.named_parameters()) + [('x', x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqj1HuBRGGZ3"
   },
   "source": [
    "## LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RY_UyS1AGGZ3",
    "outputId": "82514520-af84-4ca8-ab64-416ec001bea7"
   },
   "outputs": [],
   "source": [
    "lstm_cell = nn.LSTMCell(128, 128)\n",
    "x = torch.randn(1, 128)\n",
    "make_dot(lstm_cell(x), params=dict(list(lstm_cell.named_parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFLNmuZHGKRn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFPL_1g0GKcu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8dzlrUtGKe_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX7YT5slGKg9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OjQd4GAGKjP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qkx8tiOVGKl2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgkTf6PaGKsK",
    "outputId": "ee76fbe2-c3ef-48e1-c254-3cbfe0fe36f7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install torchviz\n",
    "from torchviz import make_dot\n",
    "\n",
    "!pip install qiskit\n",
    "import qiskit\n",
    "from qiskit import transpile, assemble\n",
    "from qiskit.visualization import *\n",
    "\n",
    "\n",
    "class QuantumCircuit:\n",
    "    \"\"\"\n",
    "    This class provides a simple interface for interaction\n",
    "    with the quantum circuit\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "\n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta = qiskit.circuit.Parameter('theta')\n",
    "\n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta, all_qubits)\n",
    "\n",
    "        self._circuit.measure_all()\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "\n",
    "    def run(self, thetas):\n",
    "        t_qc = transpile(self._circuit,\n",
    "                         self.backend)\n",
    "        qobj = assemble(t_qc,\n",
    "                        shots=self.shots,\n",
    "                        parameter_binds=[{self.theta: theta} for theta in thetas])\n",
    "        job = self.backend.run(qobj)\n",
    "        result = job.result().get_counts()\n",
    "\n",
    "        counts = np.array(list(result.values()))\n",
    "        states = np.array(list(result.keys())).astype(float)\n",
    "\n",
    "        # Compute probabilities for each state\n",
    "        probabilities = counts / self.shots\n",
    "        # Get state expectation\n",
    "        expectation = np.sum(states * probabilities)\n",
    "\n",
    "        return np.array([expectation])\n",
    "\n",
    "\n",
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
    "        result = torch.tensor([expectation_z])\n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "\n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "\n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left = ctx.quantum_circuit.run(shift_left[i])\n",
    "\n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients.append(gradient)\n",
    "        gradients = np.array([gradients]).T\n",
    "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "\n",
    "    def __init__(self, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(1, backend, shots)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQZZ8uMkGKuh"
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3qv0CJnKGKw6",
    "outputId": "56783a71-bbc7-44a5-f284-4b7843cedaff"
   },
   "outputs": [],
   "source": [
    "# Visualize the network.\n",
    "from torchviz import make_dot\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "yhat = model(x)\n",
    "make_dot(yhat, params=dict(model.named_parameters()), show_attrs=True, show_saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATWr-rpFGKzG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n95JPIs-GK1Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVWQehRqGK3r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVDoV4-sGK6L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uj-LqgdPGK8f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjR_xQRzGK-q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTyMashkGLA8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCrXr1OnGLDF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "examples.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
